<!DOCTYPE html>
<head><title>unit-1(2marks)</title></head>
<h1 style="color:greenyellow;" align="center">DEPARTMENT OF B.TECH ARTIFICIAL INTELLIGENCE AND DATA SCIENCE</h1>
<h1 style="color:blueviolet;" align="center">AD3491-FUNDAMETALS OF DATA SCIENCE AND ANALYTICS</h1>
<h2 style="color:blueviolet;" align="center">UNIT 1-INTRODUCTION TO DATA SCIENCE(2MARKS)</h2>
<hr></hr>
<h3> 1. What is Data Science?</h3>
<ul><li>Data science is a deep study of the massive amount of data, which involves extracting meaningful insights from raw, structured, and unstructured data that is processed using the scientific method, different technologies, and algorithms.</li><li> It is a multidisciplinary field that uses tools and techniques to manipulate the data so that you can find something new and meaningful.</li><li>
Data Science is about data gathering, analysis, decision-making,finding patterns in data and through analysis make future predictions.
</li></ul>
<h3>2. Where is Data Science Needed?</h3>
<p>Data Science is used in many industries in the world today, e.g. banking, consultancy, healthcare, and manufacturing.
Examples of where Data Science is needed:</p>
<ul><li>To discover the best routes to ship(For route planning).</li><li>
To foresee delays for flight/ship/train etc(through predictive analysis).</li><li>
To create promotional offers.</li><li>
To find the best suited time to deliver goods To forecast the next years revenue for a company.</li><li>
To analyze health benefit of training</li><li>
To predict who will win elections</li>
</ul>
<h3>3. Some examples for Data Science.</h3>
<p>Data Science can be applied in nearly every part of a business where data is available.
Examples are:</p>
<ul><li>Consumer Goods</li><li>
Stock markets</li><li>
Industry</li><li>
Politics</li><li>
Logistic companies</li><li>
E-commerce</li>
</ul><h3>4.What is Data and its categories?.</h3>
<p>Data is a collection of information.
One purpose of Data Science is to structure data, making it interpretable and easy to work with.
Data can be categorized into two groups:</p>
<ul><li>Structured data
</li><li>Unstructured data
</li></ul><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT57RDlqPPf3tyrJZKfCwzRtM-MNeoaeoddQw&s"width="300px" height="100px">
<h3>5.What is structured data?</h3>
<p>Structured data is data that fits neatly into data tables and includes discrete data types such as numbers, short text, and dates.</p><p>Structured data is organized and they are easier to work with.</p>
<h3>6. What is Unstructured Data?</h3>
<p>Unstructured data is not organized.We must organize the data for analysis purposes.</p><p>Unstructured data doesn't fit neatly into a data table because its size or nature: for example, audio and video files and large text documents</p>

<h3>7.How to Structure Data?</h3>
<p>We can use an array or a database table to structure or present data.</p>

<p>Example of an array:</p>
<p>[80, 85, 90, 95, 100, 105, 110, 15, 120, 125]</p>

<p>The following example shows how to create an array in Python: </p>
<p>Array =[80, 85, 90, 100, 105, 110, 115, 120, 125] </p><p>
print(Array)</p>

<h3>8.How Python is used in Data Science?</h3>

<p>Python is a  programming language widely used by Data Scientists.</p>
<p>Python has in-built mathematical libraries and functions, making it easier to calculate mathematical problems and to perform data analysis.
We will provide practical examples using Python.</p>
<h3>9.Give some Python Libraries that are used.</h3>

<p>Python has libraries with large collections of mathematical functions and analytical tools.</p>

<p>we use the libraries such as :</p>
<ul><li>Pandas - This library is used for structured data operations, like import CSV files, create dataframes, and data preparation</li><li>
Numpy-This is a mathematical library. Has a powerful N-dimensional array object, linear algebra, Fourier transform, etc.</li><li>
Matplotlib-This library is used for visualization of data.</li><li>
SciPy-This library has linear algebra modules</li></ul>

<h3>10.What are the main phases of data science life cycle?</h3>

<ul><li>Discovery</li><li>
Data preparation</li><li>
Model planning</li><li>
Model building</li><li>
Operationalize</li><li>
Communicate results</li></ul>

<h3>11.What are the tools required for data science?</h3>

<ul><li>Data Analysis tools: R, Python, Statistics, SAS, Jupyter, R Studio, MATLAB, Excel</li><li>
Data Warehousing: ETL, SQL, Hadoop, Informatica/Talend, AWS Redshift</li><li>
Data Visualization tools: R, Jupyter, Tableau, Cognos</li><li>
Machine learning tools: Spark, Mahout, Azure ML studio.</li></ul>

<h3>12.What is Data modeling?</h3>

<p>Using machine learning and statistical techniques is the step to further achieve our project goal and predict future trends. By working with clustering algorithms, we can build models to uncover trends in the data that were not distinguishable in graphs and stats. These create groups of similar events (or clusters) and more or less explicitly express what feature is decisive in these results.</p>

<h3>13.What are the facets of data science?</h3>

<ul><li>Identifying the structure of data</li><li>
Cleaning, filtering, reorganizing, augmenting, and aggregating data</li><li>
Visualizing data</li><li>
Data analysis, statistics, and modeling</li><li>
Machine Learning</li></ul>

<h3>14.List the process steps in a data science.</h3>

<ol><li>Ideate</li><li>
Explore</li><li>
Model</li><li>
Validate</li><li>
Display</li><li>
Operate</li></ol>

<h3>15.What is SMART goals framework?</h3>

<ul><li>Specific: be clear on your what's and how's</li><li>
Measurable: identify the metrics that define success </li><li>
Achievable: make it challenging but still be reachable</li><li>
Relevant: it should be important or interesting to you</li><li>
Time-bound: give it a deadline</li></ul>

<h3>16.State the process of Retrieving data.</h3>

<p>Information or data retrieval is often a continuous process during which you will consider, reconsider and refine your research problem, use various different information resources, information retrieval techniques and library services and evaluate the information you find.</p>

<h3>17.What is Data Cleaning?</h3>

<p>Data cleaning is the process of identifying and fixing incorrect data. It can be in incorrect format, duplicates, corrupt, inaccurate, incomplete, or irrelevant. Various fixes can be made to the data values representing incorrectness in the data. The data cleaning and validation steps undertaken for any data science project are implemented using a data pipeline. Each stage in a data pipeline consumes input and produces output.</p>
<h3>18.List out the common steps in the data cleaning process</h3>

<ol><li>Removing duplicates</li><li>
Remove irrelevant data</li><li>
Standardize capitalization</li><li>
Convert data type<</li><li>
Handling outliers</li><li>
Fix errors</li><li>
Language Translation</li><li>
Handle missing values</li></ol>

<h3>19.State the method of Handling Outliers.</h3>

<p>An outlier is a data point in statistics that dramatically deviates from other observations. An outlier may reflect measurement variability, or it may point to an experimental error; the latter is occasionally removed from the data set.</p>

<h3>20.How do you handle missing values?</h3>

<p>During cleaning and munging in data science, handling missing values is one of the most common tasks. The real-life data might contain missing values which need a fix before the data can be used for analysis. We can handle missing values by:</p>

<ul><li>Either removing the records that have missing value or</li>
<li>Filling the missing values using some statistical technique or by gathering data understanding.</li></ul>

<h3>21. List out the Data Cleaning Tools.</h3>

<ol><li>Microsoft Excel (Popular data cleaning tool)</li><li>

 Programming languages (Python, Ruby, SQL)</li><li>

Data Visualizations (To spot errors in your dataset)</li><li>

Proprietary software (OpenRefine, Trifacta etc.,)</li></ol>

<h3>22.Define Data Integration.</h3>

<p>Data integration is the process of merging data from several disparate sources. While performing data integration, you must work on data redundancy, inconsistency, duplicity, etc. In data mining, data integration is a record preprocessing method that includes merging data from a couple of the heterogeneous data sources into coherent data to retain and provide a unified perspective of the data.</p>

<h3>23. Why is the Data Integration Important?</h3>

<p>One of the most common applications for data integration services and technologies is market and consumer data collection. Data integration supports queries in these vast datasets, benefiting from corporate intelligence and consumer data analytics to stimulate real-time information delivery. Enterprise data integration feeds integrated data into data centers to enable enterprise reporting, predictive analytics, and business intelligence.</p>

<h3>24. Define Data transformation.</h3>

<p>Data transformation is an essential data preprocessing technique that must be performed on the data before data mining to provide patterns that are easier to understand. Data transformation changes the format, structure, or values of the data and converts them into clean, usable data. Data may be transformed at two stages of the data pipeline for data analytics projects.</p>
<h3>25. What is meant by Data Smoothing?</h3>

<p>Data smoothing is a process that is used to remove noise from the dataset using some algorithms. It allows for highlighting important features present in the dataset. It helps in predicting the patterns. When collecting data, it can be manipulated to eliminate or reduce any variance or any other noise form.</p>

<h3>26. What is exploratory data analysis? </h3>
<p>Exploratory data analysis (EDA) is used by data scientists to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods. It helps determine how best to manipulate data sources to get the answers you need, making it easier for data scientists to discover patterns, spot anomalies, test a hypothesis, or check assumptions.</p>

